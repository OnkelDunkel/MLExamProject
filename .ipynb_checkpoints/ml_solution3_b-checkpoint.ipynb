{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>dates</th>\n",
       "      <th>job-title</th>\n",
       "      <th>summary</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>advice-to-mgmt</th>\n",
       "      <th>overall-ratings</th>\n",
       "      <th>work-balance-stars</th>\n",
       "      <th>culture-values-stars</th>\n",
       "      <th>carrer-opportunities-stars</th>\n",
       "      <th>comp-benefit-stars</th>\n",
       "      <th>senior-mangemnet-stars</th>\n",
       "      <th>helpful-count</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>google</td>\n",
       "      <td>none</td>\n",
       "      <td>Dec 11, 2018</td>\n",
       "      <td>Current Employee - Anonymous Employee</td>\n",
       "      <td>best compani work</td>\n",
       "      <td>peopl smart friendli</td>\n",
       "      <td>bureaucraci slow thing</td>\n",
       "      <td>none</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.glassdoor.com/Reviews/Google-Revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>google</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>Jun 21, 2013</td>\n",
       "      <td>Former Employee - Program Manager</td>\n",
       "      <td>move speed light burn inevit</td>\n",
       "      <td>food food food cafe main campu mtv alon mini k...</td>\n",
       "      <td>work life balanc balanc perk benefit illus kee...</td>\n",
       "      <td>1) Don't dismiss emotional intelligence and ad...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2094</td>\n",
       "      <td>https://www.glassdoor.com/Reviews/Google-Revie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1 company           location          dates  \\\n",
       "0           0             1  google               none   Dec 11, 2018   \n",
       "1           1             2  google  Mountain View, CA   Jun 21, 2013   \n",
       "\n",
       "                               job-title                       summary  \\\n",
       "0  Current Employee - Anonymous Employee             best compani work   \n",
       "1      Former Employee - Program Manager  move speed light burn inevit   \n",
       "\n",
       "                                                pros  \\\n",
       "0                               peopl smart friendli   \n",
       "1  food food food cafe main campu mtv alon mini k...   \n",
       "\n",
       "                                                cons  \\\n",
       "0                             bureaucraci slow thing   \n",
       "1  work life balanc balanc perk benefit illus kee...   \n",
       "\n",
       "                                      advice-to-mgmt  overall-ratings  \\\n",
       "0                                               none              5.0   \n",
       "1  1) Don't dismiss emotional intelligence and ad...              4.0   \n",
       "\n",
       "  work-balance-stars culture-values-stars carrer-opportunities-stars  \\\n",
       "0                4.0                  5.0                        5.0   \n",
       "1                2.0                  3.0                        3.0   \n",
       "\n",
       "  comp-benefit-stars senior-mangemnet-stars  helpful-count  \\\n",
       "0                4.0                    5.0              0   \n",
       "1                5.0                    3.0           2094   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.glassdoor.com/Reviews/Google-Revie...  \n",
       "1  https://www.glassdoor.com/Reviews/Google-Revie...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"all_processed.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point there were still rows left with None or NaN values in summary, pros or cons. We went and removed these rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67519"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"summary\"].notna()]\n",
    "df = df[df[\"pros\"].notna()]\n",
    "df = df[df[\"cons\"].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 1 row was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67118"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to make it easier to work with the data we added a new column containing the text for summary, pros and cons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"summary\"].str.cat(df[\"pros\"].str.cat(df[\"cons\"],sep=\" \"),sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best compani work</td>\n",
       "      <td>peopl smart friendli</td>\n",
       "      <td>bureaucraci slow thing</td>\n",
       "      <td>best compani work peopl smart friendli bureauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>move speed light burn inevit</td>\n",
       "      <td>food food food cafe main campu mtv alon mini k...</td>\n",
       "      <td>work life balanc balanc perk benefit illus kee...</td>\n",
       "      <td>move speed light burn inevit food food food ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great balanc big compani secur fun fast move p...</td>\n",
       "      <td>softwar engin among king hill googl engin driv...</td>\n",
       "      <td>becom larger come grow pain bureaucraci slow r...</td>\n",
       "      <td>great balanc big compani secur fun fast move p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0                                  best compani work   \n",
       "1                       move speed light burn inevit   \n",
       "2  great balanc big compani secur fun fast move p...   \n",
       "\n",
       "                                                pros  \\\n",
       "0                               peopl smart friendli   \n",
       "1  food food food cafe main campu mtv alon mini k...   \n",
       "2  softwar engin among king hill googl engin driv...   \n",
       "\n",
       "                                                cons  \\\n",
       "0                             bureaucraci slow thing   \n",
       "1  work life balanc balanc perk benefit illus kee...   \n",
       "2  becom larger come grow pain bureaucraci slow r...   \n",
       "\n",
       "                                                text  \n",
       "0  best compani work peopl smart friendli bureauc...  \n",
       "1  move speed light burn inevit food food food ca...  \n",
       "2  great balanc big compani secur fun fast move p...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"summary\",\"pros\",\"cons\",\"text\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean text length in characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198.47529723770077"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df[\"text\"].str.len())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We needed a binary label to be able to predict whether a review was positive or negative. We decided to define positive reviews as a 4-star rating or leaving the rest as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df.apply(lambda row: 1 if row[\"overall-ratings\"] >= 4 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with the label column we can see that the dataset is quite unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 45483, Negative: 21635\n"
     ]
    }
   ],
   "source": [
    "df_pos = df[df[\"label\"] == 1]\n",
    "df_neg = df[df[\"label\"] == 0]\n",
    "print(\"Positive: {0}, Negative: {1}\".format(df_pos.count()[0], df_neg.count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We did a resampling in order to balance out the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_res = resample(df_pos, \n",
    "                   n_samples=df_neg.count()[0], \n",
    "                   random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21635"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos_res.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_neg.append(df_pos_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We used the TfidVectorizer from sci-kit learn to transform the strings into word vectors. We chose to only vectorize the 3000 most common words for simplicity sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "no_of_words = 3000\n",
    "cv = TfidfVectorizer(max_features=no_of_words, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43270, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cv.fit_transform(df[\"text\"].tolist())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We devided the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to reduce the dimensionality of the input data we created an autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import keras.layers as layers\n",
    "import keras.models as models\n",
    "\n",
    "encoding_dim = 32\n",
    "\n",
    "input_layer = layers.Input(shape=(no_of_words,))\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoded = layers.Dense(no_of_words, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = models.Model(input_layer, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.Model(input_layer, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "34616/34616 [==============================] - 3s 81us/step - loss: 0.6760\n",
      "Epoch 2/10\n",
      "34616/34616 [==============================] - 1s 35us/step - loss: 0.5941\n",
      "Epoch 3/10\n",
      "34616/34616 [==============================] - 1s 35us/step - loss: 0.2517\n",
      "Epoch 4/10\n",
      "34616/34616 [==============================] - 1s 35us/step - loss: 0.0693\n",
      "Epoch 5/10\n",
      "34616/34616 [==============================] - 1s 36us/step - loss: 0.0411\n",
      "Epoch 6/10\n",
      "34616/34616 [==============================] - 1s 37us/step - loss: 0.0337\n",
      "Epoch 7/10\n",
      "34616/34616 [==============================] - 1s 36us/step - loss: 0.0307\n",
      "Epoch 8/10\n",
      "34616/34616 [==============================] - 1s 37us/step - loss: 0.0293\n",
      "Epoch 9/10\n",
      "34616/34616 [==============================] - 1s 36us/step - loss: 0.0285\n",
      "Epoch 10/10\n",
      "34616/34616 [==============================] - 1s 37us/step - loss: 0.0281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08fe050be0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=10,\n",
    "                batch_size=256,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34616, 32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded = encoder.predict(X_train)\n",
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34616,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We created a function to easily run cross_val_score on the model with the correct data and print out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=4)\n",
    "def do_cross_val(model):\n",
    "    acc_score = cross_val_score(model, X_train.toarray(), y_train, cv=kf)\n",
    "    print(acc_score)\n",
    "    print(np.mean(acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We ran with various different models trying to tweak the settings for best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5349509  0.56932409 0.55257077 0.52830734 0.56672444 0.54303871\n",
      " 0.57700087 0.54550708 0.53915053 0.54406241]\n",
      "0.5500637123307313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe_knn = make_pipeline(StandardScaler(with_mean=False), KNeighborsClassifier(n_neighbors=10))\n",
    "do_cross_val(pipe_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73916811 0.75129983 0.74147891 0.74523397 0.75072213 0.75389948\n",
      " 0.74602716 0.7515169  0.73851488 0.75874025]\n",
      "0.7476601617328418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(with_mean=False), LogisticRegression(random_state=21, solver='liblinear', C=1))\n",
    "do_cross_val(pipe_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67793183 0.66955517 0.67850953 0.67677643 0.68573079 0.67215482\n",
      " 0.68361745 0.68043918 0.68939613 0.67639411]\n",
      "0.6790505443924052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_dt = make_pipeline(StandardScaler(with_mean=False), DecisionTreeClassifier(max_depth=45, random_state=21))\n",
    "do_cross_val(pipe_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69959561 0.71634893 0.70363951 0.69670711 0.71259388 0.71143847\n",
      " 0.71366657 0.70673216 0.69661947 0.70991043]\n",
      "0.7067252145763531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pipe_nb = make_pipeline(StandardScaler(with_mean=False), GaussianNB())\n",
    "do_cross_val(pipe_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the SVM classifier was very slow at training the data we trained on only 1000 samples so we could easily tweak the settings and retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = encoder.predict(X_test[:1000])\n",
    "ys = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58 0.54 0.52 0.43 0.53 0.51 0.5  0.59 0.57 0.52]\n",
      "0.5290000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_svm = make_pipeline(StandardScaler(with_mean=False), SVC(C=.1, random_state=21, kernel=\"rbf\", gamma=\"auto\"))\n",
    "acc_score = cross_val_score(pipe_svm, Xs, ys, cv=kf)\n",
    "print(acc_score)\n",
    "print(np.mean(acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all of the ML models we used the D-Tree seemed to perform the best with an accuracy of almost 60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did we manage to create a model that could answer the business question? With 60%-ish accuracy, yes.\n",
    "The accuracy of the model is not utterly impressive. We might be able to improve the predictions by using a neural network but that will be for some other time.\n",
    "However we learned a lot about Natural Language Processing and we think we will be able to do better in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
