{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Unnamed: 0.1',\n",
       " 'company',\n",
       " 'location',\n",
       " 'dates',\n",
       " 'job-title',\n",
       " 'summary',\n",
       " 'pros',\n",
       " 'cons',\n",
       " 'advice-to-mgmt',\n",
       " 'overall-ratings',\n",
       " 'work-balance-stars',\n",
       " 'culture-values-stars',\n",
       " 'carrer-opportunities-stars',\n",
       " 'comp-benefit-stars',\n",
       " 'senior-mangemnet-stars',\n",
       " 'helpful-count',\n",
       " 'link',\n",
       " 'summary_processed',\n",
       " 'summary_char_length',\n",
       " 'summary_word_count',\n",
       " 'summary_stopword_count',\n",
       " 'summary_stopword_freq',\n",
       " 'pros_processed',\n",
       " 'pros_char_length',\n",
       " 'pros_word_count',\n",
       " 'pros_stopword_count',\n",
       " 'pros_stopword_freq',\n",
       " 'cons_processed',\n",
       " 'cons_char_length',\n",
       " 'cons_word_count',\n",
       " 'cons_stopword_count',\n",
       " 'cons_stopword_freq',\n",
       " 'text',\n",
       " 'text_processed',\n",
       " 'text_char_length',\n",
       " 'text_word_count',\n",
       " 'text_stopword_count',\n",
       " 'text_stopword_freq']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"all_processed2.csv\")\n",
    "df.head(3)\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df.apply(lambda row: 1 if row[\"overall-ratings\"] >= 4 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 45607, Negative: 21792\n"
     ]
    }
   ],
   "source": [
    "df_pos = df[df[\"label\"] == 1]\n",
    "df_neg = df[df[\"label\"] == 0]\n",
    "print(\"Positive: {0}, Negative: {1}\".format(df_pos.count()[0], df_neg.count()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_res = resample(df_pos, \n",
    "                   n_samples=df_neg.count()[0], \n",
    "                   random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21792"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos_res.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_neg.append(df_pos_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We needed a binary label to be able to predict whether a review was positive or negative. We decided to define positive reviews as a 4-star rating or leaving the rest as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pros_word_count</th>\n",
       "      <th>pros_stopword_freq</th>\n",
       "      <th>pros_char_length</th>\n",
       "      <th>cons_word_count</th>\n",
       "      <th>cons_stopword_freq</th>\n",
       "      <th>cons_char_length</th>\n",
       "      <th>summary_word_count</th>\n",
       "      <th>summary_stopword_freq</th>\n",
       "      <th>summary_char_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>228.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>178.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>377.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>111.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>247.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pros_word_count  pros_stopword_freq  pros_char_length  cons_word_count  \\\n",
       "30             38.0            0.315789             228.0             13.0   \n",
       "37             31.0            0.354839             178.0             67.0   \n",
       "41              6.0            0.500000              30.0             12.0   \n",
       "48              9.0            0.111111              47.0             57.0   \n",
       "54             18.0            0.333333             111.0             41.0   \n",
       "\n",
       "    cons_stopword_freq  cons_char_length  summary_word_count  \\\n",
       "30            0.153846             104.0                 2.0   \n",
       "37            0.402985             377.0                 6.0   \n",
       "41            0.583333              76.0                 2.0   \n",
       "48            0.315789             344.0                 1.0   \n",
       "54            0.365854             247.0                 7.0   \n",
       "\n",
       "    summary_stopword_freq  summary_char_length  \n",
       "30               0.000000                 15.0  \n",
       "37               0.000000                 34.0  \n",
       "41               0.000000                  8.0  \n",
       "48               0.000000                  3.0  \n",
       "54               0.714286                 34.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_measures_indices = [\n",
    "    \"pros_word_count\", \"pros_stopword_freq\", \"pros_char_length\",\n",
    "    \"cons_word_count\", \"cons_stopword_freq\", \"cons_char_length\",\n",
    "    \"summary_word_count\", \"summary_stopword_freq\", \"summary_char_length\"\n",
    "]\n",
    "\n",
    "df2 = df[txt_measures_indices]\n",
    "#df2 = df2[:1000]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=4)\n",
    "\n",
    "def do_cross_val(model):\n",
    "    start_time = time.time()\n",
    "    acc_score = cross_val_score(model, X, y, cv=kf)\n",
    "    print(\"It took a total of {0} minutes\"\n",
    "          .format((time.time() - start_time)/60))\n",
    "    print(acc_score)\n",
    "    print(np.mean(acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn = make_pipeline(StandardScaler(with_mean=False), KNeighborsClassifier(n_neighbors=10))\n",
    "#acc = do_cross_val(pipe_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(StandardScaler(with_mean=False), LogisticRegression(random_state=21, solver='liblinear', C=1))\n",
    "#do_cross_val(pipe_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dt = make_pipeline(StandardScaler(with_mean=False), DecisionTreeClassifier(max_depth=45, random_state=21))\n",
    "#do_cross_val(pipe_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb = make_pipeline(StandardScaler(with_mean=False), GaussianNB())\n",
    "#do_cross_val(pipe_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm = make_pipeline(StandardScaler(with_mean=False), SVC(C=.1, random_state=21, kernel=\"poly\", gamma=\"auto\"))\n",
    "#do_cross_val(pipe_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm = make_pipeline(StandardScaler(with_mean=False), SVC(C=.1, random_state=21, kernel=\"linear\", gamma=\"auto\"))\n",
    "#do_cross_val(pipe_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm = make_pipeline(StandardScaler(with_mean=False), SVC(C=.1, random_state=21, kernel=\"rbf\", gamma=\"auto\"))\n",
    "#do_cross_val(pipe_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We used the TfidVectorizer from sci-kit learn to transform the strings into word vectors. We chose to only vectorize the 3000 most common words for simplicity sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "no_of_words = 3000\n",
    "tfidf = TfidfVectorizer(max_features=no_of_words, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43584, 3000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.fit_transform(df[\"text\"].tolist())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_pd = pd.DataFrame(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pros_word_count',\n",
       " 'pros_stopword_freq',\n",
       " 'pros_char_length',\n",
       " 'cons_word_count',\n",
       " 'cons_stopword_freq',\n",
       " 'cons_char_length',\n",
       " 'summary_word_count',\n",
       " 'summary_stopword_freq',\n",
       " 'summary_char_length']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   30,    37,    41,    48,    54,    61,    66,    83,    90,\n",
       "               92,\n",
       "            ...\n",
       "             1665,   861, 36104, 41078, 45657, 58115, 12708, 61485,  8717,\n",
       "            18851],\n",
       "           dtype='int64', length=43584)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.concat([df2,pd.DataFrame(index = df2.index, data = X.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pros_word_count</th>\n",
       "      <th>pros_stopword_freq</th>\n",
       "      <th>pros_char_length</th>\n",
       "      <th>cons_word_count</th>\n",
       "      <th>cons_stopword_freq</th>\n",
       "      <th>cons_char_length</th>\n",
       "      <th>summary_word_count</th>\n",
       "      <th>summary_stopword_freq</th>\n",
       "      <th>summary_char_length</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>2990</th>\n",
       "      <th>2991</th>\n",
       "      <th>2992</th>\n",
       "      <th>2993</th>\n",
       "      <th>2994</th>\n",
       "      <th>2995</th>\n",
       "      <th>2996</th>\n",
       "      <th>2997</th>\n",
       "      <th>2998</th>\n",
       "      <th>2999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>228.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>178.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>377.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.096456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>111.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>247.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3009 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pros_word_count  pros_stopword_freq  pros_char_length  cons_word_count  \\\n",
       "30             38.0            0.315789             228.0             13.0   \n",
       "37             31.0            0.354839             178.0             67.0   \n",
       "41              6.0            0.500000              30.0             12.0   \n",
       "48              9.0            0.111111              47.0             57.0   \n",
       "54             18.0            0.333333             111.0             41.0   \n",
       "\n",
       "    cons_stopword_freq  cons_char_length  summary_word_count  \\\n",
       "30            0.153846             104.0                 2.0   \n",
       "37            0.402985             377.0                 6.0   \n",
       "41            0.583333              76.0                 2.0   \n",
       "48            0.315789             344.0                 1.0   \n",
       "54            0.365854             247.0                 7.0   \n",
       "\n",
       "    summary_stopword_freq  summary_char_length         0  ...      2990  2991  \\\n",
       "30               0.000000                 15.0  0.000000  ...  0.000000   0.0   \n",
       "37               0.000000                 34.0  0.000000  ...  0.000000   0.0   \n",
       "41               0.000000                  8.0  0.000000  ...  0.000000   0.0   \n",
       "48               0.000000                  3.0  0.096456  ...  0.227332   0.0   \n",
       "54               0.714286                 34.0  0.000000  ...  0.000000   0.0   \n",
       "\n",
       "    2992  2993  2994  2995  2996  2997  2998      2999  \n",
       "30   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "37   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.115659  \n",
       "41   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "48   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "54   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "\n",
       "[5 rows x 3009 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We devided the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to reduce the dimensionality of the input data we created an autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We created a function to easily run cross_val_score on the model with the correct data and print out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=4)\n",
    "def do_cross_val(model):\n",
    "    start_time = time.time()\n",
    "    acc_score = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    print(\"It took a total of {0} minutes\"\n",
    "          .format((time.time() - start_time)/60))\n",
    "    print(acc_score)\n",
    "    print(np.mean(acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We ran with various different models trying to tweak the settings for best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took a total of 1.0395310282707215 minutes\n",
      "[0.77688557 0.76914253 0.75336966 0.76570118 0.7611127  0.76484084\n",
      " 0.75738457 0.7541595  0.75272519 0.76821572]\n",
      "0.7623537453513508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(with_mean=False), LogisticRegression(random_state=21, solver='liblinear', C=1))\n",
    "do_cross_val(pipe_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took a total of 3.0553784092267353 minutes\n",
      "[0.70834528 0.70605105 0.70203613 0.72813307 0.70863206 0.70318325\n",
      " 0.71866934 0.70682731 0.71342513 0.72145726]\n",
      "0.7116759882333217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_dt = make_pipeline(DecisionTreeClassifier(max_depth=45, random_state=21))\n",
    "do_cross_val(pipe_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took a total of 0.41800847053527834 minutes\n",
      "[0.73788357 0.73272154 0.72096358 0.73415543 0.73128764 0.72985374\n",
      " 0.73300832 0.72576018 0.72776822 0.74842226]\n",
      "0.7321824476816686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pipe_nb = make_pipeline(GaussianNB())\n",
    "do_cross_val(pipe_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_1,1 3000 mixed standardscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pros_word_count</th>\n",
       "      <th>pros_stopword_freq</th>\n",
       "      <th>pros_char_length</th>\n",
       "      <th>cons_word_count</th>\n",
       "      <th>cons_stopword_freq</th>\n",
       "      <th>cons_char_length</th>\n",
       "      <th>summary_word_count</th>\n",
       "      <th>summary_stopword_freq</th>\n",
       "      <th>summary_char_length</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>2990</th>\n",
       "      <th>2991</th>\n",
       "      <th>2992</th>\n",
       "      <th>2993</th>\n",
       "      <th>2994</th>\n",
       "      <th>2995</th>\n",
       "      <th>2996</th>\n",
       "      <th>2997</th>\n",
       "      <th>2998</th>\n",
       "      <th>2999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6457</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>162.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15293</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>86.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>211.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.099945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10640</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>167.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149457</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25298</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>39.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>702.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56508</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>204.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>377.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3009 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pros_word_count  pros_stopword_freq  pros_char_length  cons_word_count  \\\n",
       "6457              28.0            0.321429             162.0             31.0   \n",
       "15293             14.0            0.428571              86.0             33.0   \n",
       "10640             29.0            0.620690             167.0             27.0   \n",
       "25298              7.0            0.428571              39.0            110.0   \n",
       "56508             28.0            0.321429             204.0             68.0   \n",
       "\n",
       "       cons_stopword_freq  cons_char_length  summary_word_count  \\\n",
       "6457             0.709677             150.0                 1.0   \n",
       "15293            0.303030             211.0                23.0   \n",
       "10640            0.444444             160.0                 1.0   \n",
       "25298            0.436364             702.0                12.0   \n",
       "56508            0.529412             377.0                 5.0   \n",
       "\n",
       "       summary_stopword_freq  summary_char_length         0  ...  2990  2991  \\\n",
       "6457                0.000000                  4.0  0.000000  ...   0.0   0.0   \n",
       "15293               0.521739                 97.0  0.099945  ...   0.0   0.0   \n",
       "10640               0.000000                  5.0  0.000000  ...   0.0   0.0   \n",
       "25298               0.416667                 58.0  0.000000  ...   0.0   0.0   \n",
       "56508               0.600000                 17.0  0.000000  ...   0.0   0.0   \n",
       "\n",
       "       2992      2993  2994  2995  2996  2997      2998  2999  \n",
       "6457    0.0  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0  \n",
       "15293   0.0  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0  \n",
       "10640   0.0  0.153686   0.0   0.0   0.0   0.0  0.149457   0.0  \n",
       "25298   0.0  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0  \n",
       "56508   0.0  0.000000   0.0   0.0   0.0   0.0  0.000000   0.0  \n",
       "\n",
       "[5 rows x 3009 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "text_vec_indices = [str(i) for i in range(no_of_words)]\n",
    "txt_measures_indices\n",
    "\n",
    "def select_txt_measures(X):\n",
    "    return X[:, :9]\n",
    "\n",
    "def select_txt_vectors(X):\n",
    "    return X[:, 9:]\n",
    "\n",
    "pipe_lr = make_pipeline(\n",
    "    #FunctionTransformer(select_txt_measures, validate = True),\n",
    "    StandardScaler(with_mean=False), \n",
    "    LogisticRegression(random_state=21, solver='liblinear', C=1)\n",
    ")\n",
    "pipe_nb = make_pipeline(\n",
    "    #FunctionTransformer(select_txt_vectors, validate = True),\n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "voting_c = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', pipe_lr), \n",
    "        ('rf', pipe_nb),\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took a total of 1.3889941533406576 minutes\n",
      "[0.73903069 0.73358188 0.72125036 0.73616289 0.73415543 0.73386866\n",
      " 0.7332951  0.72920252 0.72977625 0.75043029]\n",
      "0.734075406052906\n"
     ]
    }
   ],
   "source": [
    "do_cross_val(voting_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the SVM classifier was very slow at training the data we trained on only 1000 samples so we could easily tweak the settings and retrain the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all of the ML models we used the D-Tree seemed to perform the best with an accuracy of almost 60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did we manage to create a model that could answer the business question? With 60%-ish accuracy, yes.\n",
    "The accuracy of the model is not utterly impressive. We might be able to improve the predictions by using a neural network but that will be for some other time.\n",
    "However we learned a lot about Natural Language Processing and we think we will be able to do better in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
